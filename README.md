# üîÆ DataLexir

[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![Python Version](https://img.shields.io/badge/python-3.8%2B-blue)](https://www.python.org/downloads/)
[![PyPI version](https://badge.fury.io/py/datalexir.svg)](https://badge.fury.io/py/datalexir)

> **Une biblioth√®que Python r√©volutionnaire pour l'exploration interactive de donn√©es et la g√©n√©ration automatique de pipelines**

DataLexir transforme votre processus d'exploration de donn√©es en permettant de travailler sur des √©chantillons l√©gers dans des notebooks Jupyter, puis de g√©n√©rer automatiquement des pipelines de production pour Pandas et Spark.

## üéØ Vision

DataLexir r√©sout un probl√®me majeur des gestionnaires de donn√©es : **comment explorer efficacement de gros volumes de donn√©es et transformer cette exploration en pipeline de production reproductible ?**

### ‚ú® Fonctionnalit√©s cl√©s

- üî¨ **Exploration interactive** : Travaillez sur des √©chantillons de donn√©es dans des notebooks
- üèóÔ∏è **G√©n√©ration automatique de pipelines** : Convertissez votre exploration en code de production
- ‚ö° **Multi-moteur** : Support de Pandas et Apache Spark
- üéÆ **Interface intuitive** : Widgets interactifs pour une exploration sans code
- üìä **Tra√ßabilit√© compl√®te** : Historique d√©taill√© de toutes les transformations

## üöÄ Installation

### Via pip (recommand√©)

```bash
pip install datalexir
```

### Installation en mode d√©veloppement

```bash
git clone https://github.com/remiv1/data_elexir.git
cd data_elexir
pip install -e .
```

## üèóÔ∏è Architecture

DataLexir est organis√© en trois modules principaux :

### üìö `elexbook` - Exploration Interactive

Module d'exploration de donn√©es avec √©chantillonnage intelligent pour les notebooks Jupyter.

**Fonctionnalit√©s :**

- √âchantillonnage intelligent des datasets volumineux
- Interface interactive avec widgets Jupyter
- Historique automatique des transformations
- Assignation dynamique des types de colonnes

### üêº `elexdas` - Pipeline Pandas

G√©n√©rateur et ex√©cuteur de pipelines pour Pandas.

**Fonctionnalit√©s :**

- Conversion des explorations en pipelines Pandas
- Optimisation automatique des op√©rations
- Support complet de l'√©cosyst√®me Pandas

### ‚ö° `elexpark` - Pipeline Spark

G√©n√©rateur et ex√©cuteur de pipelines pour Apache Spark.

**Fonctionnalit√©s :**

- Conversion des explorations en pipelines Spark
- Optimisation pour les gros volumes de donn√©es
- Distribution automatique des calculs

## üìã Guide d'utilisation rapide

### 1. Exploration avec Elexbook

```python
import pandas as pd
from datalexir.elexbook import Elexbook

# Chargement d'un dataset volumineux
df = pd.read_csv('mon_gros_dataset.csv')

# Cr√©ation d'un elexbook avec √©chantillonnage (30% par d√©faut)
book = Elexbook(df, sample=0.1)

# Exploration interactive
book.head()
book.describe()
book.dropna()
book.fillna(0)

# Interface interactive pour les types de colonnes
book.dynamic_type_assignment()

# G√©n√©ration du pipeline
pipeline = book.concatbook()
```

### 2. Application avec Elexdas (Pandas)

```python
from datalexir.elexdas import Elexdas

# Application du pipeline sur les donn√©es compl√®tes
elexdas = Elexdas(df)
result = elexdas.pipeline(pipeline)
```

### 3. Application avec Elexpark (Spark)

```python
from datalexir.elexpark import Elexpark
from pyspark.sql import SparkSession

# Initialisation Spark
spark = SparkSession.builder.appName("DataLexir").getOrCreate()
sdf = spark.read.csv('mon_gros_dataset.csv', header=True, inferSchema=True)

# Application du pipeline sur Spark
elexpark = Elexpark(sdf)
result = elexpark.pipeline(pipeline)
```

## üéØ Cas d'usage : Analyse de donn√©es de ventes

Imaginez que vous √™tes gestionnaire de donn√©es dans une entreprise de e-commerce avec 10 millions de transactions :

```python
# 1. Exploration sur √©chantillon (100k transactions)
from datalexir.elexbook import Elexbook
import pandas as pd

# Chargement des donn√©es
sales_data = pd.read_csv('sales_10M_rows.csv')
print(f"Dataset complet : {len(sales_data):,} lignes")

# Exploration interactive sur 1% des donn√©es
book = Elexbook(sales_data, sample=0.01)
print(f"√âchantillon : {len(book.sample):,} lignes")

# Nettoyage interactif
book.dropna(subset=['customer_id', 'amount'])
book.fillna({'category': 'Unknown'})
book.astype({'amount': 'float64'})

# Analyse exploratoire
book.groupby('category')['amount'].sum().sort_values(ascending=False)
book.plot(x='date', y='amount', kind='line')

# G√©n√©ration du pipeline
cleaning_pipeline = book.concatbook()
```

```python
# 2. Application en production sur les 10M de lignes
from datalexir.elexdas import Elexdas

# Application du pipeline sur toutes les donn√©es
processor = Elexdas(sales_data)
clean_sales_data = processor.pipeline(cleaning_pipeline)

# Ou pour de tr√®s gros volumes avec Spark
from datalexir.elexpark import Elexpark
spark_processor = Elexpark(spark_sales_data)
clean_sales_data_spark = spark_processor.pipeline(cleaning_pipeline)
```

## üîß Installation des d√©pendances

### D√©pendances principales

```bash
pip install pandas numpy ipywidgets jupyter
```

### Pour le support Spark (optionnel)

```bash
pip install pyspark
```

### Pour le d√©veloppement

```bash
pip install -r requirements-dev.txt
```


## üìö Documentation

Pour une documentation compl√®te, consultez :

- [Guide de d√©marrage rapide](documentation/guide-demarrage.md)
- [R√©f√©rence API](documentation/api-reference.md)
- [Exemples d'utilisation](documentation/exemples.md)
- [Notebooks de d√©monstration](notebooks/)

## ü§ù Contribuer

Nous encourageons les contributions ! DataLexir est un projet open source en pleine croissance.

### Comment contribuer

1. **Fork** le repository
2. **Cr√©ez** une branche pour votre fonctionnalit√© (`git checkout -b feature/ma-nouvelle-fonctionnalite`)
3. **Committez** vos changements (`git commit -m 'Ajout d'une nouvelle fonctionnalit√©'`)
4. **Pushez** vers la branche (`git push origin feature/ma-nouvelle-fonctionnalite`)
5. **Ouvrez** une Pull Request

### Directives de contribution

- Suivez les conventions de code Python (PEP 8)
- Ajoutez des tests pour toutes les nouvelles fonctionnalit√©s
- Documentez vos changements
- Assurez-vous que tous les tests passent

Pour plus de d√©tails, consultez [CONTRIBUTING.md](CONTRIBUTING.md).

## üë• √âquipe

**Cr√©ateur et mainteneur principal**:

- **R√©mi Verschuur** ([@remiv1](https://github.com/remiv1)) - *Cr√©ateur et architecte principal*

### Rejoignez l'√©quipe !

Nous recherchons des contributeurs passionn√©s pour faire grandir DataLexir. Si vous √™tes int√©ress√© par :

- Le d√©veloppement Python
- L'ing√©nierie des donn√©es
- L'UX/UI pour les outils de donn√©es
- La documentation technique

N'h√©sitez pas √† nous contacter !

## üìÑ Licence

Ce projet est sous licence Apache License 2.0. Voir le fichier [LICENSE](LICENSE) pour plus de d√©tails.

```txt
Copyright 2025 DataLexir Contributors

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
```

## üéØ Roadmap

Bien qu'aucune roadmap formelle ne soit d√©finie pour le moment, les prochaines √©tapes incluront :

- Am√©lioration de l'interface utilisateur interactive
- Support de formats de donn√©es suppl√©mentaires
- Optimisation des performances
- Documentation √©tendue et tutoriels

---

‚≠ê **Si DataLexir vous aide dans vos projets, n'h√©sitez pas √† nous donner une √©toile sur GitHub !**

## üîó Liens utiles

- [Issues GitHub](https://github.com/remiv1/data_elexir/issues)
- [Discussions](https://github.com/remiv1/data_elexir/discussions)
- [PyPI Package](https://pypi.org/project/datalexir/)
