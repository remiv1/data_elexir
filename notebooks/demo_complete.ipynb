{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "095b18df",
   "metadata": {},
   "source": [
    "# üîÆ DataLexir - D√©monstration Compl√®te\n",
    "\n",
    "Ce notebook d√©montre l'utilisation compl√®te de DataLexir pour l'exploration de donn√©es et la g√©n√©ration de pipelines.\n",
    "\n",
    "## üìã Sommaire\n",
    "\n",
    "1. [Installation et Import](#installation)\n",
    "2. [Pr√©paration des Donn√©es](#donn√©es)\n",
    "3. [Exploration avec Elexbook](#exploration)\n",
    "4. [G√©n√©ration du Pipeline](#pipeline)\n",
    "5. [Application avec Elexdas (Pandas)](#elexdas)\n",
    "6. [Application avec Elexpark (Spark)](#elexpark)\n",
    "7. [Conclusion](#conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc2e6da",
   "metadata": {},
   "source": [
    "<a id=\"installation\"></a>\n",
    "## 1. üì¶ Installation et Import\n",
    "\n",
    "Commen√ßons par installer et importer les biblioth√®ques n√©cessaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7459bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation (si n√©cessaire)\n",
    "# !pip install datalexir\n",
    "\n",
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Import DataLexir\n",
    "from datalexir.elexbook import Elexbook\n",
    "# from datalexir.elexdas import Elexdas\n",
    "# from datalexir.elexpark import Elexpark\n",
    "\n",
    "print(\"‚úÖ Imports r√©ussis !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa81eeb",
   "metadata": {},
   "source": [
    "<a id=\"donn√©es\"></a>\n",
    "## 2. üìä Pr√©paration des Donn√©es\n",
    "\n",
    "Cr√©ons un dataset de d√©monstration simulant des donn√©es de ventes e-commerce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a819c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# G√©n√©ration d'un dataset de d√©monstration\n",
    "np.random.seed(42)\n",
    "n_records = 100000  # 100k enregistrements pour simuler un gros dataset\n",
    "\n",
    "# G√©n√©ration des donn√©es\n",
    "data = {\n",
    "    'transaction_id': [f'T{i:06d}' for i in range(1, n_records + 1)],\n",
    "    'customer_id': [f'C{np.random.randint(1, 10000):05d}' for _ in range(n_records)],\n",
    "    'product_category': np.random.choice(['Electronics', 'Clothing', 'Books', 'Home', 'Sports', None], n_records, p=[0.25, 0.2, 0.15, 0.2, 0.15, 0.05]),\n",
    "    'amount': np.random.lognormal(3, 1, n_records),\n",
    "    'quantity': np.random.randint(1, 10, n_records),\n",
    "    'date': [datetime(2024, 1, 1) + timedelta(days=np.random.randint(0, 365)) for _ in range(n_records)],\n",
    "    'payment_method': np.random.choice(['Credit Card', 'PayPal', 'Bank Transfer', 'Cash'], n_records, p=[0.5, 0.3, 0.15, 0.05]),\n",
    "    'discount_applied': np.random.choice([True, False], n_records, p=[0.3, 0.7]),\n",
    "    'customer_rating': np.random.choice([1, 2, 3, 4, 5, None], n_records, p=[0.05, 0.1, 0.15, 0.35, 0.3, 0.05])\n",
    "}\n",
    "\n",
    "# Ajout de quelques valeurs manquantes\n",
    "missing_indices = np.random.choice(n_records, size=int(n_records * 0.02), replace=False)\n",
    "for idx in missing_indices:\n",
    "    data['amount'][idx] = None\n",
    "\n",
    "# Cr√©ation du DataFrame\n",
    "sales_df = pd.DataFrame(data)\n",
    "\n",
    "print(f\"üìä Dataset g√©n√©r√© : {len(sales_df):,} lignes x {len(sales_df.columns)} colonnes\")\n",
    "print(f\"üíæ Taille en m√©moire : {sales_df.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n",
    "sales_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1f52be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aper√ßu du dataset\n",
    "print(\"üìà Informations sur le dataset :\")\n",
    "print(sales_df.info())\n",
    "print(\"\\nüìä Statistiques descriptives :\")\n",
    "sales_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525400fd",
   "metadata": {},
   "source": [
    "<a id=\"exploration\"></a>\n",
    "## 3. üîç Exploration avec Elexbook\n",
    "\n",
    "Maintenant, utilisons Elexbook pour explorer ce dataset sur un √©chantillon plus petit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de6147a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©ation d'un Elexbook avec 5% du dataset\n",
    "book = Elexbook(sales_df, sample=0.05)\n",
    "\n",
    "print(f\"üìñ Elexbook cr√©√© !\")\n",
    "print(f\"üìä Dataset original : {len(book.df):,} lignes\")\n",
    "print(f\"üéØ √âchantillon : {len(book.sample):,} lignes ({len(book.sample)/len(book.df)*100:.1f}%)\")\n",
    "print(f\"üìù Historique : {len(book.history)} op√©rations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3a5295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploration de base\n",
    "print(\"üîç Aper√ßu de l'√©chantillon :\")\n",
    "book.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb122a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# V√©rification des valeurs manquantes\n",
    "print(\"‚ùì Valeurs manquantes dans l'√©chantillon :\")\n",
    "book.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e8f958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nettoyage des donn√©es\n",
    "print(\"üßπ Nettoyage des donn√©es...\")\n",
    "\n",
    "# Suppression des lignes avec des montants manquants\n",
    "book.dropna(subset=['amount'])\n",
    "print(f\"‚úÖ Suppression des montants manquants : {len(book.sample)} lignes restantes\")\n",
    "\n",
    "# Remplissage des cat√©gories manquantes\n",
    "book.fillna({'product_category': 'Unknown'})\n",
    "print(f\"‚úÖ Remplissage des cat√©gories manquantes\")\n",
    "\n",
    "# Remplissage des notes manquantes avec la m√©diane\n",
    "median_rating = book.sample['customer_rating'].median()\n",
    "book.fillna({'customer_rating': median_rating})\n",
    "print(f\"‚úÖ Remplissage des notes manquantes avec la m√©diane ({median_rating})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67e34b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversions de types\n",
    "print(\"üîÑ Conversion des types...\")\n",
    "\n",
    "# Conversion des types\n",
    "book.astype({\n",
    "    'amount': 'float64',\n",
    "    'customer_rating': 'int64',\n",
    "    'discount_applied': 'bool'\n",
    "})\n",
    "\n",
    "print(\"‚úÖ Types convertis\")\n",
    "print(\"\\nüìä Types apr√®s conversion :\")\n",
    "print(book.sample.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d630c3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse exploratoire\n",
    "print(\"üìà Analyse par cat√©gorie de produit :\")\n",
    "category_analysis = book.groupby('product_category')['amount'].agg(['count', 'mean', 'sum']).round(2)\n",
    "print(category_analysis)\n",
    "\n",
    "print(\"\\nüí≥ Analyse par m√©thode de paiement :\")\n",
    "payment_analysis = book.groupby('payment_method')['amount'].agg(['count', 'mean']).round(2)\n",
    "print(payment_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45353380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation simple\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "book.sample['product_category'].value_counts().plot(kind='bar')\n",
    "plt.title('Distribution des Cat√©gories de Produits')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "book.sample['amount'].hist(bins=30)\n",
    "plt.title('Distribution des Montants')\n",
    "plt.xlabel('Montant')\n",
    "plt.ylabel('Fr√©quence')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143c567e",
   "metadata": {},
   "source": [
    "<a id=\"pipeline\"></a>\n",
    "## 4. ‚öôÔ∏è G√©n√©ration du Pipeline\n",
    "\n",
    "Maintenant, g√©n√©rons le pipeline √† partir de notre exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1a0c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# G√©n√©ration du pipeline\n",
    "pipeline = book.concatbook()\n",
    "\n",
    "print(\"üîß Pipeline g√©n√©r√© !\")\n",
    "print(f\"üìù Nombre d'op√©rations : {len(book.history)}\")\n",
    "print(\"\\nüìã Historique des op√©rations :\")\n",
    "for i, operation in enumerate(book.history, 1):\n",
    "    print(f\"{i}. {operation['operation']} - {operation['arguments']}\")\n",
    "\n",
    "print(\"\\n‚öôÔ∏è Pipeline structure :\")\n",
    "print(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7ba497",
   "metadata": {},
   "source": [
    "<a id=\"elexdas\"></a>\n",
    "## 5. üêº Application avec Elexdas (Pandas)\n",
    "\n",
    "Appliquons maintenant le pipeline sur le dataset complet avec Elexdas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0d953f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Elexdas n'est pas encore impl√©ment√©, voici une simulation\n",
    "print(\"üêº Simulation d'Elexdas...\")\n",
    "print(\"\\nüîÑ Application du pipeline sur le dataset complet...\")\n",
    "\n",
    "# Simulation de l'application du pipeline\n",
    "processed_df = sales_df.copy()\n",
    "\n",
    "# Application manuelle des op√©rations du pipeline\n",
    "print(\"1. Suppression des montants manquants...\")\n",
    "processed_df = processed_df.dropna(subset=['amount'])\n",
    "print(f\"   ‚úÖ {len(processed_df):,} lignes restantes\")\n",
    "\n",
    "print(\"2. Remplissage des cat√©gories manquantes...\")\n",
    "processed_df['product_category'] = processed_df['product_category'].fillna('Unknown')\n",
    "print(\"   ‚úÖ Cat√©gories remplies\")\n",
    "\n",
    "print(\"3. Remplissage des notes manquantes...\")\n",
    "median_rating_full = processed_df['customer_rating'].median()\n",
    "processed_df['customer_rating'] = processed_df['customer_rating'].fillna(median_rating_full)\n",
    "print(f\"   ‚úÖ Notes remplies avec la m√©diane ({median_rating_full})\")\n",
    "\n",
    "print(\"4. Conversion des types...\")\n",
    "processed_df = processed_df.astype({\n",
    "    'amount': 'float64',\n",
    "    'customer_rating': 'int64',\n",
    "    'discount_applied': 'bool'\n",
    "})\n",
    "print(\"   ‚úÖ Types convertis\")\n",
    "\n",
    "print(f\"\\nüéØ Dataset final : {len(processed_df):,} lignes\")\n",
    "print(f\"üíæ Taille en m√©moire : {processed_df.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7f9303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaison avant/apr√®s\n",
    "print(\"üìä Comparaison avant/apr√®s traitement :\")\n",
    "print(\"\\nAvant :\")\n",
    "print(sales_df.info())\n",
    "print(\"\\nApr√®s :\")\n",
    "print(processed_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82baff76",
   "metadata": {},
   "source": [
    "<a id=\"elexpark\"></a>\n",
    "## 6. ‚ö° Application avec Elexpark (Spark)\n",
    "\n",
    "Pour les tr√®s gros volumes, nous pourrions utiliser Elexpark avec Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3978348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Elexpark n'est pas encore impl√©ment√©, voici une simulation\n",
    "print(\"‚ö° Simulation d'Elexpark avec Spark...\")\n",
    "print(\"\\nüí° Pour des datasets de plusieurs millions de lignes, Elexpark permettrait :\")\n",
    "print(\"   ‚Ä¢ Distribution automatique des calculs\")\n",
    "print(\"   ‚Ä¢ Optimisation des requ√™tes\")\n",
    "print(\"   ‚Ä¢ Gestion de la m√©moire pour les gros volumes\")\n",
    "print(\"   ‚Ä¢ Traitement parall√®le sur plusieurs machines\")\n",
    "\n",
    "# Exemple de code Elexpark (quand il sera impl√©ment√©)\n",
    "spark_code = '''\n",
    "# Code Elexpark futur\n",
    "from pyspark.sql import SparkSession\n",
    "from datalexir.elexpark import Elexpark\n",
    "\n",
    "# Initialisation Spark\n",
    "spark = SparkSession.builder.appName(\"DataLexir\").getOrCreate()\n",
    "spark_df = spark.createDataFrame(sales_df)\n",
    "\n",
    "# Application du pipeline\n",
    "elexpark = Elexpark(spark_df)\n",
    "result_spark = elexpark.pipeline(pipeline)\n",
    "\n",
    "# Collecte des r√©sultats\n",
    "final_df = result_spark.toPandas()\n",
    "'''\n",
    "\n",
    "print(\"\\nüìù Exemple de code Elexpark :\")\n",
    "print(spark_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b8fdd1",
   "metadata": {},
   "source": [
    "<a id=\"conclusion\"></a>\n",
    "## 7. üéØ Conclusion\n",
    "\n",
    "Cette d√©monstration montre le workflow complet de DataLexir :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d872282",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üéØ R√©sum√© du workflow DataLexir :\")\n",
    "print(\"\\n1. üìä Dataset original : 100,000 lignes\")\n",
    "print(f\"2. üîç Exploration sur √©chantillon : {len(book.sample):,} lignes (5%)\")\n",
    "print(f\"3. üßπ Nettoyage interactif : {len(book.history)} op√©rations\")\n",
    "print(f\"4. ‚öôÔ∏è Pipeline g√©n√©r√© automatiquement\")\n",
    "print(f\"5. üêº Application avec Pandas : {len(processed_df):,} lignes trait√©es\")\n",
    "print(f\"6. ‚ö° Possibilit√© d'utiliser Spark pour de plus gros volumes\")\n",
    "\n",
    "print(\"\\n‚ú® Avantages de DataLexir :\")\n",
    "print(\"   ‚Ä¢ Exploration rapide sur √©chantillons\")\n",
    "print(\"   ‚Ä¢ Interface interactive dans Jupyter\")\n",
    "print(\"   ‚Ä¢ G√©n√©ration automatique de pipelines\")\n",
    "print(\"   ‚Ä¢ Reproductibilit√© garantie\")\n",
    "print(\"   ‚Ä¢ Scalabilit√© avec Pandas et Spark\")\n",
    "print(\"   ‚Ä¢ Tra√ßabilit√© compl√®te des transformations\")\n",
    "\n",
    "print(\"\\nüöÄ DataLexir : De l'exploration √† la production en quelques lignes !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f39fc8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìö Ressources suppl√©mentaires\n",
    "\n",
    "- [Documentation DataLexir](https://github.com/remiv1/data_elexir)\n",
    "- [Guide de contribution](https://github.com/remiv1/data_elexir/blob/main/CONTRIBUTING.md)\n",
    "- [Exemples suppl√©mentaires](https://github.com/remiv1/data_elexir/tree/main/notebooks)\n",
    "\n",
    "**N'h√©sitez pas √† ‚≠ê le projet sur GitHub si DataLexir vous aide !**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
